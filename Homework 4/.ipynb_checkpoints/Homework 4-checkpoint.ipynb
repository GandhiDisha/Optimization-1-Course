{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 4 - Disha Gandhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It costs a company $12 to purchase an hour of labor and $15 to purchase an hour of capital. If L hours of labor and K units of capital are available, then 0.05L2/3K1/3 machines can be produced. Suppose the company has $100,000 to purchase labor and capital. What is the maximum number of machines it can produce? Round to the nearest whole number of machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function will be minimized\n",
    "def neg_machines(resources):    \n",
    "    #resources[0] = labor\n",
    "    #resources[1] = capital\n",
    "    return (-0.05*(resources[0]**(2/3))*(resources[1]**(1/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inequality constraints must be >= 0\n",
    "def confun(resources):\n",
    "    return (-12*resources[0]-15*resources[1]+100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "constr1 = {'type':'ineq', 'fun': confun}\n",
    "constraints = [constr1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_resources = minimize(neg_machines,[1000,1000],constraints=constraints) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5555.49858657, 2222.26779733])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display solution\n",
    "opt_resources.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204.66841656722596"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display objective\n",
    "-opt_resources.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file homework4stocks.csv Download homework4stocks.csv contains historical monthly returns for 27 companies. The first row contains stock names, and the first column contains the dates. For each company, calculate the estimated mean return and the estimated variance of return. Then calculate the estimated covariances between the companies' returns. Find a portfolio that achieves an expected monthly return of at least 1% and minimizes portfolio variance.  Assume no short selling is allowed. What is the portfolio's standard deviation?  Round to 2 decimal places?  Answer in terms of absolute numbers.  If your answer is 8% then you should enter 0.08.\n",
    "\n",
    " \n",
    "\n",
    "We may or may not get to the content for this problem before it's due.  If we don't then don't worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "df = pd.read_csv(r'.\\homework4stocks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_return = 0.01\n",
    "nstocks = len(df.columns)-1\n",
    "meanvec = df.mean(axis = 0)\n",
    "Sigma = df.cov()\n",
    "\n",
    "w = np.ones(nstocks)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function will be minimized\n",
    "def obj_fun(x):\n",
    "    return np.sqrt(x @ Sigma @ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inequality constraints must be >= 0\n",
    "def mean_con_fun(x):\n",
    "    return (x @ meanvec) - threshold_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equality constraints must be =0\n",
    "def all_invest_con(x):\n",
    "    return np.sum(x)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "con1 = {'type':'eq', 'fun': all_invest_con}\n",
    "con2 = {'type':'ineq', 'fun': mean_con_fun}\n",
    "cons = [con1,con2]\n",
    "bds = [(0,1)]*nstocks # all weights must be between 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_port = minimize(obj_fun,w,constraints=cons,bounds=bds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.53243847e-18, 5.23351725e-02, 4.95543802e-17, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.70268571e-18,\n",
       "       0.00000000e+00, 4.62422629e-18, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.24283433e-02, 2.45309627e-17, 1.11054206e-17, 1.83460538e-02,\n",
       "       9.90654330e-18, 0.00000000e+00, 1.39606635e-01, 0.00000000e+00,\n",
       "       2.68842608e-01, 4.54576600e-18, 1.09636664e-17, 1.22490157e-01,\n",
       "       6.13443375e-02, 5.26744181e-18, 3.14606692e-01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_port.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02973481385164782"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "opt_port.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file variable_selection.csv Download variable_selection.csv contains observations of variables y, x1, x2, and x3. Here, y is the dependent variable. We want to choose a linear model that uses at most two independent variables such that the sum of squared residuals is minimized. This can be formulated as a constrained quadratic programming problem.\n",
    " \n",
    "\n",
    "This is called best subset problem that is usually very hard to solve. We will solve this problem by enumeration. Run six OLS regressions (3 with one independent variable and three more with two variables each) and choose the regression that best fits the data. You can run each regression in R using the lm routine. \n",
    "\n",
    " \n",
    "\n",
    "Which variables are included?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each case, we run the ordinary linear regression and then we choose the one with the smallest sum of squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'.\\variable_selection.csv')\n",
    "SSE = np.zeros(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['x1']]\n",
    "y = df['y']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X).fit()\n",
    "predictions = model.predict(X)\n",
    "SSE[0] = sum(np.square(predictions - y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['x2']]\n",
    "y = df['y']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X).fit()\n",
    "predictions = model.predict(X)\n",
    "SSE[1] = sum(np.square(predictions - y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['x3']]\n",
    "y = df['y']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X).fit()\n",
    "predictions = model.predict(X)\n",
    "SSE[2] = sum(np.square(predictions - y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['x1','x2']]\n",
    "y = df['y']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X).fit()\n",
    "predictions = model.predict(X)\n",
    "SSE[3] = sum(np.square(predictions - y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['x1','x3']]\n",
    "y = df['y']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X).fit()\n",
    "predictions = model.predict(X)\n",
    "SSE[4] = sum(np.square(predictions - y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['x2','x3']]\n",
    "y = df['y']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X).fit()\n",
    "predictions = model.predict(X)\n",
    "SSE[5] = sum(np.square(predictions - y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7901.29942878,  878.83582325, 8575.63588048,   26.1908733 ,\n",
       "       7860.08875973,  878.18105044])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the 4th pair has the smallest sum of squared error, we chose it. The relative coefficients are 2.9992, 3.9692 and 0, which is super close to the true values $\\beta_1 = 3, \\beta_2 = 4, \\beta_3 = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file nflratings.csv Download nflratings.csv contains the results of 256 regular-season NFL games from the 2009 season. The teams are indexed 1 to 32 as shown below:\n",
    "\n",
    "The csv data file contains a matrix with the following columns:\n",
    "\n",
    "• Week (1-17)\n",
    "• Home Team Index (1-32 from the table above)\n",
    "\n",
    "• Visiting Team Index (1-32 from the table above)\n",
    "\n",
    "• Home Team Score\n",
    "• Visiting Team Score\n",
    "\n",
    "For example, the first game in the matrix is team 25 Pittsburgh versus team 31 Tennessee, played at Pittsburgh. Pittsburgh won the game by a score of 13 to 10, and the point spread (home team score minus visitor team score) is 3. A positive point spread means that the home team won; a negative point spread indicates that the visiting team won.\n",
    "\n",
    "The goal of this problem is to determine a set of ratings for the 32 NFL teams that most accurately predicts the actual outcomes of the games played, similar to homework 1. Here however, we will also incorporate a 'home field advantage' that adds some number of points to the predicted point spread.  Use NLP to find the ratings that best predict the actual point spreads observed. The model will estimate the home team advantage and the ratings.  The model accounts for the home team advantage by adding a constant (which you need to solve for) to the predicted point spread.  The objective is to minimize the sum of squared prediction errors. You will need to calculate the following:\n",
    "\n",
    "• Actual Point Spread = Home Team Score – Visiting Team Score\n",
    "\n",
    "• Predicted Spread = Home Team Rating – Visitor Team Rating + Home Team Advantage\n",
    "\n",
    "• Prediction error = Actual Point Spread – Predicted Point Spread\n",
    "\n",
    "Your goal is to minimize: Screen Shot 2021-03-22 at 10.22.05 AM.png  \n",
    "\n",
    "You will also need to normalize the ratings (like you did in HW1). To do this, you set the actual average of the ratings to be 85 (this is somewhat arbitrary but based on the well-known Sagarin rating system). What do these ratings mean: If two teams had ratings of 82 and 91, then the second team would be predicted to win by 9 points if the game was played on a neutral field. \n",
    "\n",
    "Formulate this as an NLP and solve it.\n",
    "\n",
    "How many games (of the 256 played) does this model predict the winner correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the $i^{th}$ team's rating be $x_i$. the actual average of the ratings being 85 is equivalent to \n",
    "\\begin{align}\n",
    "\\dfrac{\\sum_{i=1}^{32}x_i}{32} = 85.\n",
    "\\end{align}\n",
    "Rearrange it to have \n",
    "\\begin{align}\n",
    "x_{32}=85\\times 32 - \\sum_{i=1}^{32}x_i.\n",
    "\\end{align}\n",
    "That is to say, instead of having 32 team ratings, we only need the first 31, and the last one can be calculated. Besides the ratings, the home team advantage is also a variable. As a result, there are 32 variables in total. The initial value to use for optimization is that all the ratings are the same, namely 85, and there is no home team advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'.\\nflratings.csv',header=None)\n",
    "df.columns = ['week','home','away','hscore','vscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSE(xopt):\n",
    "    #The last element of x is the home team advantage\n",
    "    home_advantage = xopt[31]\n",
    "    #Because the avg. rating is 85, the rating of the last team can be calc. from\n",
    "    #other 31 teams\n",
    "    x = np.concatenate((np.transpose(xopt[0:31]),np.array([85*32-sum(xopt[0:31])])))\n",
    "    N = len(df.week)\n",
    "    \n",
    "    SSE = 0\n",
    "    for i in range(0,N):\n",
    "        pred_spread = x[df.home[i]-1] - x[df.away[i]-1] + home_advantage\n",
    "        real_spread = df.hscore[i] - df.vscore[i]\n",
    "        SSE = SSE + (pred_spread - real_spread)**2\n",
    "    \n",
    "    return SSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84.52234186 89.84144149 92.7456974  83.08898822 88.75995403 79.81205271\n",
      " 87.5440603  76.88699868 92.12111605 85.63576823 70.50405571 92.25557363\n",
      " 86.98432736 90.86235067 78.43978422 76.88819569 86.61526752 92.06483461\n",
      " 96.122671   95.6286823  85.09888047 93.1484154  75.0328585  90.95814514\n",
      " 86.64232697 67.71996264 92.60581806 85.24192731 74.73183618 79.17109122\n",
      " 82.18828627  2.17273049]\n",
      "42925.67976864548\n"
     ]
    }
   ],
   "source": [
    "ini = np.concatenate((85*np.ones(31),np.zeros(1)))\n",
    "opt = minimize(SSE,ini) \n",
    "print(opt.x)\n",
    "print(opt.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = np.concatenate((np.transpose(opt.x[0:31]),np.array([85*32-sum(opt.x[0:31])])))\n",
    "home_advantage = opt.x[31]\n",
    "\n",
    "N = len(df)\n",
    "pred_spread = np.zeros(N)\n",
    "\n",
    "for i in range(0,N):\n",
    "    pred_spread[i] = rank[df.home[i]-1] - rank[df.away[i]-1] + home_advantage\n",
    "    \n",
    "real_spread = df.hscore-df.vscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70703125"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result = (pred_spread >= 0)\n",
    "real_result = (real_spread >= 0)\n",
    "\n",
    "precision = sum(pred_result == real_result)/N\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>r</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>72</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>38</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "r      False  True \n",
       "p                  \n",
       "False     72     37\n",
       "True      38    109"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The confusion matrix is:\")\n",
    "pd.crosstab(pred_result,real_result,rownames='p',colnames='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Correct predictions:\")\n",
    "72+109"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
